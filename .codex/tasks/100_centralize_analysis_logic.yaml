# yaml-language-server: $schema=https://json.schemastore.org/github-issue-forms.json
name: "Task 100: Centralize Analysis Logic (run_full_analysis)"
description: "Introduce consolidated analysis helper and refactor call sites"
title: "[Task 100] Centralize Analysis Logic (run_full_analysis)"
labels:
  - dashboard
  - ux
  - "priority: High"
  - "status: todo"
  - "task:100"
body:
  - type: markdown
    attributes:
      value: |
        ## Summary
        Reduce redundancy across dashboard modules by introducing a consolidated `run_full_analysis(cfg)` helper that returns sorting, case/dups, diffs, and projected changes in a single, consistent schema.

  - type: markdown
    attributes:
      value: |
        ## Details
        The analysis flow (sorting checks, case/dups, projections, and diff) is recomputed in multiple places (`callbacks.py`, `reports.py`, and on load`). Create a single function (e.g., in `analysis.py` or a new `analysis_helpers.py`) that performs the full analysis and returns a normalized structure consumed by both UI and report generation.

        - Define `run_full_analysis(cfg)` returning:
          - `sorting_issues`, `case_dups`, `projected_changes`, `diff`, `projected_diff_summary`.
        - Refactor call sites in `callbacks.py` and `reports.py` to use it.
        - Ensure no functionality loss in existing UI sections and exports.
        - Add minimal tests around the helper (unit-level) if patterns exist.

  - type: checkboxes
    id: acceptance_criteria
    attributes:
      label: Acceptance Criteria
      options:
        - label: "A single helper computes the full analysis without side effects"
        - label: "callbacks.py and reports.py call the helper instead of duplicating logic"
        - label: "ECAQ and Diff exports produce identical content as before"
        - label: "No regressions in UI metrics, issues lists, or projections"

  - type: markdown
    attributes:
      value: |
        ## Out of Scope
        - Performance optimization beyond code deduplication.
        - Any changes to on-disk report formats.

  - type: markdown
    attributes:
      value: |
        ## How to Verify
        - Implement helper and refactor call sites; run: `python -m scripts.dashboard --dev test`
        - Generate reports before and after change: `python -m scripts.dashboard --report all`; compare outputs
        - Launch dashboard: `python -m scripts.dashboard` and verify metrics, issues, and projections render
        - Trigger Fix All, Export ECAQ, and Export Diff; confirm outputs are identical in content to baseline
        - Review code to ensure `callbacks.py` and `reports.py` now delegate to the helper

  - type: markdown
    attributes:
      value: |
        ## Plan
        - Draft `run_full_analysis(cfg)` returning sorting, case/dups, projected changes, diff
        - Refactor callbacks.py/report paths to use the helper
        - Re-run tests and regenerate reports to compare outputs

  - type: markdown
    attributes:
      value: |
        ## References
        - scripts/dashboard/callbacks.py:1
        - scripts/dashboard/reports.py:1
        - scripts/dashboard/analysis.py:1
        - scripts/dashboard/TODO_dashboard.md
        - issues/generated/100_üîÅ_Centralize_Analysis_Logic.md

  - type: markdown
    attributes:
      value: |
        ## Estimate
        0.5‚Äì1.0 day

  - type: markdown
    attributes:
      value: |
        ## Commands
        ```bash
        python -m scripts.dashboard --dev test
        python -m scripts.dashboard --report all
        python -m scripts.dashboard --launch
        ```
